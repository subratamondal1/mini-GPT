{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1340f24",
   "metadata": {
    "papermill": {
     "duration": 0.011343,
     "end_time": "2023-09-02T08:02:57.633203",
     "exception": false,
     "start_time": "2023-09-02T08:02:57.621860",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Bigram Language Model\n",
    "**Learns how words follow each other in sentences.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6be6ee2",
   "metadata": {
    "papermill": {
     "duration": 0.010514,
     "end_time": "2023-09-02T08:02:57.654392",
     "exception": false,
     "start_time": "2023-09-02T08:02:57.643878",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Download the Book **Wizard of OZ** as .txt file from [here.](https://github.com/subratamondal1/mini-GPT/raw/main/src/mini_gpt/data/wizard%20of%20oz.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bc271bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T08:02:57.680207Z",
     "iopub.status.busy": "2023-09-02T08:02:57.679272Z",
     "iopub.status.idle": "2023-09-02T08:03:01.894853Z",
     "shell.execute_reply": "2023-09-02T08:03:01.893510Z"
    },
    "papermill": {
     "duration": 4.233209,
     "end_time": "2023-09-02T08:03:01.898825",
     "exception": false,
     "start_time": "2023-09-02T08:02:57.665616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# Hyperparameters\n",
    "block_size = 8 # means that each training example will consist of a sequence of 8 consecutive tokens from input data\n",
    "batch_size = 4 # each batch will contain 4 training examples (sequence of 8 consecutive tokens)\n",
    "learning_rate = 3e-4\n",
    "max_iterations = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71697ad8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T08:03:01.926054Z",
     "iopub.status.busy": "2023-09-02T08:03:01.923968Z",
     "iopub.status.idle": "2023-09-02T08:03:04.574076Z",
     "shell.execute_reply": "2023-09-02T08:03:04.572495Z"
    },
    "papermill": {
     "duration": 2.666124,
     "end_time": "2023-09-02T08:03:04.577305",
     "exception": false,
     "start_time": "2023-09-02T08:03:01.911181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-09-02 08:03:02--  https://github.com/subratamondal1/mini-GPT/raw/main/src/mini_gpt/data/wizard%20of%20oz.txt\r\n",
      "Resolving github.com (github.com)... 20.27.177.113\r\n",
      "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://raw.githubusercontent.com/subratamondal1/mini-GPT/main/src/mini_gpt/data/wizard%20of%20oz.txt [following]\r\n",
      "--2023-09-02 08:03:03--  https://raw.githubusercontent.com/subratamondal1/mini-GPT/main/src/mini_gpt/data/wizard%20of%20oz.txt\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 217429 (212K) [text/plain]\r\n",
      "Saving to: ‘wizard of oz.txt’\r\n",
      "\r\n",
      "wizard of oz.txt    100%[===================>] 212.33K  --.-KB/s    in 0.1s    \r\n",
      "\r\n",
      "2023-09-02 08:03:04 (1.79 MB/s) - ‘wizard of oz.txt’ saved [217429/217429]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! wget \"https://github.com/subratamondal1/mini-GPT/raw/main/src/mini_gpt/data/wizard%20of%20oz.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e12a3a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T08:03:04.605495Z",
     "iopub.status.busy": "2023-09-02T08:03:04.604770Z",
     "iopub.status.idle": "2023-09-02T08:03:05.726005Z",
     "shell.execute_reply": "2023-09-02T08:03:05.724568Z"
    },
    "papermill": {
     "duration": 1.139538,
     "end_time": "2023-09-02T08:03:05.728772",
     "exception": false,
     "start_time": "2023-09-02T08:03:04.589234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/kaggle\u001b[00m\r\n",
      "├── \u001b[01;34minput\u001b[00m\r\n",
      "├── \u001b[01;34mlib\u001b[00m\r\n",
      "│   └── \u001b[01;34mkaggle\u001b[00m\r\n",
      "│       └── gcp.py\r\n",
      "├── \u001b[01;34msrc\u001b[00m\r\n",
      "│   └── script.ipynb\r\n",
      "└── \u001b[01;34mworking\u001b[00m\r\n",
      "    ├── __notebook__.ipynb\r\n",
      "    └── wizard of oz.txt\r\n",
      "\r\n",
      "5 directories, 4 files\r\n"
     ]
    }
   ],
   "source": [
    "! tree /kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92c262e",
   "metadata": {
    "papermill": {
     "duration": 0.012019,
     "end_time": "2023-09-02T08:03:05.753313",
     "exception": false,
     "start_time": "2023-09-02T08:03:05.741294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Open the file **Wizard of OZ.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f822079c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T08:03:05.779719Z",
     "iopub.status.busy": "2023-09-02T08:03:05.778748Z",
     "iopub.status.idle": "2023-09-02T08:03:05.788200Z",
     "shell.execute_reply": "2023-09-02T08:03:05.786521Z"
    },
    "papermill": {
     "duration": 0.027257,
     "end_time": "2023-09-02T08:03:05.792354",
     "exception": false,
     "start_time": "2023-09-02T08:03:05.765097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the text: 207797.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(file = \"/kaggle/working/wizard of oz.txt\", mode = \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "print(f\"Length of the text: {len(text)}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dfc44aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T08:03:05.821075Z",
     "iopub.status.busy": "2023-09-02T08:03:05.820624Z",
     "iopub.status.idle": "2023-09-02T08:03:05.827146Z",
     "shell.execute_reply": "2023-09-02T08:03:05.825580Z"
    },
    "papermill": {
     "duration": 0.024236,
     "end_time": "2023-09-02T08:03:05.829961",
     "exception": false,
     "start_time": "2023-09-02T08:03:05.805725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Wonderful Wizard of Oz\n",
      "\n",
      "by L. Frank Baum\n",
      "\n",
      "\n",
      "This book is dedicated to my good friend & comrade\n",
      "My Wife\n",
      "L.F.B.\n",
      "\n",
      "\n",
      "Contents\n",
      "\n",
      " Introduction\n",
      " Chapter I. The Cyclone\n",
      " Chapter II. The Council with the Mu\n"
     ]
    }
   ],
   "source": [
    "# First 200 texts\n",
    "print(text[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b33a905",
   "metadata": {
    "papermill": {
     "duration": 0.013664,
     "end_time": "2023-09-02T08:03:05.856847",
     "exception": false,
     "start_time": "2023-09-02T08:03:05.843183",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Convert the texts into `characters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba475e22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T08:03:05.884839Z",
     "iopub.status.busy": "2023-09-02T08:03:05.883844Z",
     "iopub.status.idle": "2023-09-02T08:03:05.896132Z",
     "shell.execute_reply": "2023-09-02T08:03:05.894411Z"
    },
    "papermill": {
     "duration": 0.029541,
     "end_time": "2023-09-02T08:03:05.898967",
     "exception": false,
     "start_time": "2023-09-02T08:03:05.869426",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set doesn't allow duplicates, hence the decreased len(text): 72\n",
      "\n",
      "['\\n', ' ', '!', '&', '(', ')', ',', '-', '.', '0', '1', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '—', '‘', '’', '“', '”']\n",
      "\n",
      "Vocabulary Size is 72\n"
     ]
    }
   ],
   "source": [
    "# Convert the texts into `unique characters`.\n",
    "unique_chars = sorted(set(text))\n",
    "vocabulary_size = len(unique_chars)\n",
    "print(f\"Set doesn't allow duplicates, hence the decreased len(text): {len(unique_chars)}\\n\\n{unique_chars}\")\n",
    "print(f\"\\nVocabulary Size is {vocabulary_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf15a10",
   "metadata": {
    "papermill": {
     "duration": 0.011972,
     "end_time": "2023-09-02T08:03:05.924123",
     "exception": false,
     "start_time": "2023-09-02T08:03:05.912151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Character Tokenization\n",
    "**Character Level Tokenizer** converts the input text data into tokens of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4acb37b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T08:03:05.951514Z",
     "iopub.status.busy": "2023-09-02T08:03:05.950717Z",
     "iopub.status.idle": "2023-09-02T08:03:05.960223Z",
     "shell.execute_reply": "2023-09-02T08:03:05.959001Z"
    },
    "papermill": {
     "duration": 0.026503,
     "end_time": "2023-09-02T08:03:05.963063",
     "exception": false,
     "start_time": "2023-09-02T08:03:05.936560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Text:\t [33, 35, 16, 32, 15, 34, 15, 1, 27, 29, 28, 18, 15, 26]\n",
      "Decoded Text:\t SUBRATA MONDAL\n"
     ]
    }
   ],
   "source": [
    "string_to_int = {char:index for index, char in enumerate(unique_chars)}\n",
    "int_to_string = {index:char for index, char in enumerate(unique_chars)}\n",
    "\n",
    "# Encoder & Decoder\n",
    "encode = lambda input_Text: [string_to_int[char] for char in input_Text]\n",
    "decode = lambda input_Data: \"\".join([int_to_string[integer] for integer in input_Data])\n",
    "\n",
    "encoded_string = encode(\"SUBRATA MONDAL\")\n",
    "decoded_string = decode(encode(\"SUBRATA MONDAL\"))\n",
    "\n",
    "print(f\"Encoded Text:\\t {encoded_string}\\nDecoded Text:\\t {decoded_string}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91549cb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T08:03:05.989563Z",
     "iopub.status.busy": "2023-09-02T08:03:05.989164Z",
     "iopub.status.idle": "2023-09-02T08:03:05.997787Z",
     "shell.execute_reply": "2023-09-02T08:03:05.996336Z"
    },
    "papermill": {
     "duration": 0.025221,
     "end_time": "2023-09-02T08:03:06.000555",
     "exception": false,
     "start_time": "2023-09-02T08:03:05.975334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def character_tokenization(input_text:str, unique_chars):\n",
    "    string_to_int = {char:i for i, char in enumerate(unique_chars)}\n",
    "    int_to_string = {i:char for i, char in enumerate(unique_chars)}\n",
    "\n",
    "    # Encoder & Decoder\n",
    "    encode = lambda S: [string_to_int[c] for c in S]\n",
    "    decode = lambda L: \"\".join([int_to_string[i] for i in L])\n",
    "\n",
    "    encoded_string = encode(input_text)\n",
    "    decoded_string = decode(encode(input_text))\n",
    "    \n",
    "    return input_text, encoded_string, decoded_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "266eeb4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T08:03:06.030055Z",
     "iopub.status.busy": "2023-09-02T08:03:06.029332Z",
     "iopub.status.idle": "2023-09-02T08:03:06.038537Z",
     "shell.execute_reply": "2023-09-02T08:03:06.036590Z"
    },
    "papermill": {
     "duration": 0.026337,
     "end_time": "2023-09-02T08:03:06.040828",
     "exception": false,
     "start_time": "2023-09-02T08:03:06.014491",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text:\t SUBRATA MONDAL\n",
      "Encoded Text:\t [33, 35, 16, 32, 15, 34, 15, 1, 27, 29, 28, 18, 15, 26]\n",
      "Decoded Text:\t SUBRATA MONDAL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "character_tokens = character_tokenization(input_text=\"SUBRATA MONDAL\", unique_chars = unique_chars)\n",
    "\n",
    "print(f\"Input Text:\\t {character_tokens[0]}\\nEncoded Text:\\t {character_tokens[1]}\\nDecoded Text:\\t {character_tokens[2]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9a07f3",
   "metadata": {
    "papermill": {
     "duration": 0.012233,
     "end_time": "2023-09-02T08:03:06.065831",
     "exception": false,
     "start_time": "2023-09-02T08:03:06.053598",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Convert the whole text data into PyTorch Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54184e19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T08:03:06.094419Z",
     "iopub.status.busy": "2023-09-02T08:03:06.094034Z",
     "iopub.status.idle": "2023-09-02T08:03:06.176945Z",
     "shell.execute_reply": "2023-09-02T08:03:06.175979Z"
    },
    "papermill": {
     "duration": 0.100189,
     "end_time": "2023-09-02T08:03:06.179449",
     "exception": false,
     "start_time": "2023-09-02T08:03:06.079260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([207797])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(data=encode(text), dtype=torch.long)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038a6a9a",
   "metadata": {
    "papermill": {
     "duration": 0.013571,
     "end_time": "2023-09-02T08:03:06.207220",
     "exception": false,
     "start_time": "2023-09-02T08:03:06.193649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "How Bigram Language Models work at a fundamental level.\n",
    "* It generates input sequences and their corresponding target outputs for the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f93ac7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T08:03:06.235401Z",
     "iopub.status.busy": "2023-09-02T08:03:06.234882Z",
     "iopub.status.idle": "2023-09-02T08:03:06.288017Z",
     "shell.execute_reply": "2023-09-02T08:03:06.286555Z"
    },
    "papermill": {
     "duration": 0.070197,
     "end_time": "2023-09-02T08:03:06.290839",
     "exception": false,
     "start_time": "2023-09-02T08:03:06.220642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When Input is tensor([0]) then target is 34\n",
      "When Input is tensor([ 0, 34]) then target is 48\n",
      "When Input is tensor([ 0, 34, 48]) then target is 45\n",
      "When Input is tensor([ 0, 34, 48, 45]) then target is 1\n",
      "When Input is tensor([ 0, 34, 48, 45,  1]) then target is 37\n",
      "When Input is tensor([ 0, 34, 48, 45,  1, 37]) then target is 55\n",
      "When Input is tensor([ 0, 34, 48, 45,  1, 37, 55]) then target is 54\n",
      "When Input is tensor([ 0, 34, 48, 45,  1, 37, 55, 54]) then target is 44\n"
     ]
    }
   ],
   "source": [
    "# How Bigram Language Models work at a fundamental level.\n",
    "prediction_X = data[:block_size] \n",
    "target_y = data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    input_text = prediction_X[:t+1]\n",
    "    target = target_y[t]\n",
    "    print(f\"When Input is {input_text} then target is {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d06622",
   "metadata": {
    "papermill": {
     "duration": 0.012835,
     "end_time": "2023-09-02T08:03:06.316412",
     "exception": false,
     "start_time": "2023-09-02T08:03:06.303577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c021901b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T08:03:06.344527Z",
     "iopub.status.busy": "2023-09-02T08:03:06.344151Z",
     "iopub.status.idle": "2023-09-02T08:03:06.386652Z",
     "shell.execute_reply": "2023-09-02T08:03:06.385073Z"
    },
    "papermill": {
     "duration": 0.059937,
     "end_time": "2023-09-02T08:03:06.389570",
     "exception": false,
     "start_time": "2023-09-02T08:03:06.329633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n is 166237\n",
      "\n",
      "inputs --- torch.Size([4, 8]) --- \n",
      "tensor([[53,  1, 41, 54, 64, 49, 55, 61],\n",
      "        [ 1, 54, 45, 45, 44, 52, 45, 59],\n",
      "        [41, 62, 49, 54, 47,  1, 59, 48],\n",
      "        [ 0, 18, 55,  1, 52, 45, 60,  1]])\n",
      "\n",
      "targets --- torch.Size([4, 8]) --- \n",
      "tensor([[ 1, 41, 54, 64, 49, 55, 61, 59],\n",
      "        [54, 45, 45, 44, 52, 45, 59,  1],\n",
      "        [62, 49, 54, 47,  1, 59, 48, 41],\n",
      "        [18, 55,  1, 52, 45, 60,  1, 53]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = int(0.8 * len(data))\n",
    "print(f\"n is {n}\")\n",
    "\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# generate batches of training or validation data\n",
    "def get_batch(split): \n",
    "    data = train_data if split == \"train\" else val_data\n",
    "    ix = torch.randint(high=len(data) - block_size, size = (batch_size,))\n",
    "    \n",
    "    x = torch.stack(tensors=[ data[i: i+block_size] for i in ix])\n",
    "    y = torch.stack(tensors=[ data[i+1: i+block_size+1] for i in ix])\n",
    "    return x.to(device), y.to(device) # move x,y to gpu if available\n",
    "\n",
    "# x is inputs, y is target or label\n",
    "x,y = get_batch(\"train\")\n",
    "print(f\"\\ninputs --- {x.shape} --- \\n{x}\\n\")\n",
    "print(f\"targets --- {y.shape} --- \\n{y}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1259a2c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T05:24:11.638470Z",
     "iopub.status.busy": "2023-09-02T05:24:11.638016Z",
     "iopub.status.idle": "2023-09-02T05:24:11.647782Z",
     "shell.execute_reply": "2023-09-02T05:24:11.646137Z",
     "shell.execute_reply.started": "2023-09-02T05:24:11.638433Z"
    },
    "papermill": {
     "duration": 0.01272,
     "end_time": "2023-09-02T08:03:06.415307",
     "exception": false,
     "start_time": "2023-09-02T08:03:06.402587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Neural Network\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7316eca2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T08:03:06.443754Z",
     "iopub.status.busy": "2023-09-02T08:03:06.443288Z",
     "iopub.status.idle": "2023-09-02T08:03:06.450541Z",
     "shell.execute_reply": "2023-09-02T08:03:06.448493Z"
    },
    "papermill": {
     "duration": 0.025005,
     "end_time": "2023-09-02T08:03:06.453678",
     "exception": false,
     "start_time": "2023-09-02T08:03:06.428673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac91b18c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T08:03:06.483337Z",
     "iopub.status.busy": "2023-09-02T08:03:06.482844Z",
     "iopub.status.idle": "2023-09-02T08:03:06.621219Z",
     "shell.execute_reply": "2023-09-02T08:03:06.619646Z"
    },
    "papermill": {
     "duration": 0.156129,
     "end_time": "2023-09-02T08:03:06.624049",
     "exception": false,
     "start_time": "2023-09-02T08:03:06.467920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "u—pAguCH!FS?bAWdzM1\n",
      "et’TqT;J,HE1C!Q)xf!dJQOPVawLsIzXFtXFhh“ ’z:xNU;OC—Z!?B&ZhBvng,G1kopeNhns\n",
      "RQp“miW0p?HvazhwqLQl;“QtOwmB?zXAQp—)SU-“V&JQtG?V.Lcy—d’NGCl9k’ggTflI\n",
      "I\n",
      "peqDjIX&nILlGQBgv ANaVp(Qt,Sjo.drxRfSs—‘V !w1?ZDJn&YF1\n",
      "&‘rWLlMxaBjwmLGksdGV&,KGVl’iFmCXJ—r!Jh(cGR9wecN jPD;if9nTDb:XtNsBUEQ-fjQt,-lBZZDPw;E\n",
      "ILBZ0xzU;aL1Rf(qUETSI1q9lUSy—d”hmOIQIo(KVTe?S“s)VnvYrV TSk0d\n",
      "gZ(zZyvxgTSxahY09lwd9 TdVqQkf?STPB;ze;gJ,GXe;Pgtm.X&j:xKjxfKAm?ZS(b,!p!rkbrje(w—;Lnby—m!hifBjSsQk0MgT‘eADd:DL”ThgIgY(HlGU&kh(z)pb1V’Jd0\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocabulary_size):\n",
    "        super(BigramLanguageModel, self).__init__()\n",
    "        self.tokens_embedding_table = nn.Embedding(num_embeddings=vocabulary_size, embedding_dim=vocabulary_size)\n",
    "        \n",
    "    def forward(self, input_tokens, targets=None):\n",
    "        logits = self.tokens_embedding_table(input_tokens)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            batch_size, tokens_in_a_sequence, vocabulary_size = logits.shape\n",
    "            logits = logits.view(batch_size * tokens_in_a_sequence, vocabulary_size)\n",
    "            targets = targets.view(batch_size * tokens_in_a_sequence)\n",
    "            loss = F.cross_entropy(input=logits, target=targets)\n",
    "        \n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, input_tokens, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self.forward(input_tokens) # get predictions\n",
    "            # focus only on the last sequence\n",
    "            logits = logits[:, -1, : ] # becomes (batch_size,vocabulary_size)\n",
    "            # apply softmax to get probabilities\n",
    "            probabilities = F.softmax(input=logits, dim = -1) # (batch_size, tokens_in_a_sequence+1)\n",
    "            # sample from the distribution\n",
    "            input_tokens_next = torch.multinomial(input = probabilities, num_samples=1) # (batch_size, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            input_tokens = torch.cat((input_tokens, input_tokens_next), dim=1) # (B, tokens_in_a_sequence + 1)\n",
    "            \n",
    "        return input_tokens\n",
    "    \n",
    "model = BigramLanguageModel(vocabulary_size=vocabulary_size)\n",
    "m = model.to(device)\n",
    "\n",
    "input_tokens = torch.zeros(size=(1,1), dtype=torch.long, device=device)\n",
    "generated_charts = decode(m.generate(input_tokens = input_tokens, max_new_tokens=500)[0].tolist())\n",
    "print(generated_charts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614a5022",
   "metadata": {
    "papermill": {
     "duration": 0.013112,
     "end_time": "2023-09-02T08:03:06.650663",
     "exception": false,
     "start_time": "2023-09-02T08:03:06.637551",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Optimizer\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf45bb6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T08:03:06.678724Z",
     "iopub.status.busy": "2023-09-02T08:03:06.678336Z",
     "iopub.status.idle": "2023-09-02T08:03:06.684437Z",
     "shell.execute_reply": "2023-09-02T08:03:06.683245Z"
    },
    "papermill": {
     "duration": 0.023058,
     "end_time": "2023-09-02T08:03:06.686920",
     "exception": false,
     "start_time": "2023-09-02T08:03:06.663862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb6acbd",
   "metadata": {
    "papermill": {
     "duration": 0.012573,
     "end_time": "2023-09-02T08:03:06.713365",
     "exception": false,
     "start_time": "2023-09-02T08:03:06.700792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Loop\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "176acefc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T08:03:06.742407Z",
     "iopub.status.busy": "2023-09-02T08:03:06.741970Z",
     "iopub.status.idle": "2023-09-02T08:03:06.856316Z",
     "shell.execute_reply": "2023-09-02T08:03:06.854692Z"
    },
    "papermill": {
     "duration": 0.13292,
     "end_time": "2023-09-02T08:03:06.859084",
     "exception": false,
     "start_time": "2023-09-02T08:03:06.726164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is 4.8312201499938965\n"
     ]
    }
   ],
   "source": [
    "for iter in range(max_iterations):\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch(\"train\")\n",
    "    \n",
    "    # loss evaluation\n",
    "    logits, loss = model.forward(input_tokens=xb, targets=yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(f\"Loss is {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "689e5ffd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T08:03:06.888048Z",
     "iopub.status.busy": "2023-09-02T08:03:06.887621Z",
     "iopub.status.idle": "2023-09-02T08:03:06.963701Z",
     "shell.execute_reply": "2023-09-02T08:03:06.961956Z"
    },
    "papermill": {
     "duration": 0.093178,
     "end_time": "2023-09-02T08:03:06.966262",
     "exception": false,
     "start_time": "2023-09-02T08:03:06.873084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ro—rVN&lfE!)WrEV1nVBKdw0&k—Tqv-vWhw 09KN’K!WbAXKqsuZzPqIVk-“b9Sh\n",
      "eGZDOIz9m!vdRe“TixqLRKxep“9kqeLHILnm”Wj&Q.TEpbYK0-u\n",
      "GI ID!ELHO\n",
      "caSb)jNXg!LG—iIpuG)(zlnBTeO‘eO:WZhwqtyA!‘tXTLH?S“x&CJ—Oqo,w’9BZAhwElzvKZyeuDWV&CL.\n",
      "Y?veY’\n",
      "Hpv-NNjJbLP!Q1k0,xr\n",
      "i\n",
      "-NS“9k—jzJH-NJusSr c!S?E\n",
      "-ljf’RXDgBWpeMk’!y—cU&k xv“rFKx’1gk0ZWp&iarVrxrZ9QdN‘ep?c“dx-”Z”qKS?excUDcEWLhF.xp”1’YKCdN0hX-”TYR-E1”-Crv)’WaE1x1Bu!”,!y—“bmsdAX”qZm.“Baht.hwpcWav’Y“SBkXJ-NaBq”—‘00aVrgaW;oZXnI Tze) Ym.\n",
      "”iNGX ?DcM;Rz”PuGiLGVZ’KkEjN,Zf”t xyloW0ZJmsP’w—\n"
     ]
    }
   ],
   "source": [
    "input_tokens = torch.zeros(size=(1,1), dtype=torch.long, device=device)\n",
    "generated_charts = decode(m.generate(input_tokens = input_tokens, max_new_tokens=500)[0].tolist())\n",
    "print(generated_charts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dddcff8",
   "metadata": {
    "papermill": {
     "duration": 0.012764,
     "end_time": "2023-09-02T08:03:06.992721",
     "exception": false,
     "start_time": "2023-09-02T08:03:06.979957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "kernelspec": {
  "display_name": "Python 3",
  "language": "python",
  "name": "python3"
 },
 "language_info": {
  "codemirror_mode": {
   "name": "ipython",
   "version": 3
  },
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "nbconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": "3.6.4"
 },
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.424455,
   "end_time": "2023-09-02T08:03:08.032962",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-02T08:02:53.608507",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
